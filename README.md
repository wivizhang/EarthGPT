# üåè EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain

Official repository for [EarthGPT](https://arxiv.org/abs/2401.16822). :smile: 

Authors: Wei Zhang*, Miaoxin Cai*, Tong Zhang, Yin Zhuang, and Xuerui Mao
* The authors contributed equally to this work.
  
## :mega: News
- [2024.10.21]: We open source the dataset MMRS-1M! :fire::fire::fire:
- [2024.05.25]: EarthGPT has been accepted to IEEE-TGRS üéâ 
- [2024.04.29]: We partially released the data of MMRS-1M! 
* [2024.01.30]: The paper for EarthGPT is released [arxiv](https://arxiv.org/abs/2401.16822). 

##  :sparkles: Introduction
EarthGPT is a pioneering model designed to seamlessly unify multi-sensor and diverse remote sensing intelligent visual interpretation tasks in a unified framework, guided by user language instructions. EarthGPT is versatile at performing visual-language dialogues across optical, SAR, and infrared images. EarthGPT's capabilities extend to a wide range of tasks including scene classification, image description, visual question answering, target description, visual localization, and object detection.

##  :sparkles: MMRS-1M: Multi-modal Multi-sensor Remote Sensing Instruction Dataset

<u>___The entire data of MMRS-1M is released! üöÄ___</u>

MMRS-1M is the largest multi-modal multi-sensor RS instruction-following dataset, consisting of over 1M image-text pairs that include optical, SAR, and infrared RS images. 

We release over 1M image-text pairs in the following link.

LinkÔºöhttps://pan.baidu.com/s/1sK9I862tuQfiiFbHBvOOpw?pwd=mycu 

PWdÔºömycu

### Datasets Usage guidelines






## :bookmark: Citation
```bash
@article{zhang2024earthgpt,
  title={Earthgpt: A universal multi-modal large language model for multi-sensor image comprehension in remote sensing domain},
  author={Zhang, Wei and Cai, Miaoxin and Zhang, Tong and Zhuang, Yin and Mao, Xuerui},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}
```

## :memo: Acknowledgment
This paper benefits from [llama](https://github.com/facebookresearch/llama). Thanks for their wonderful work.

## :envelope: Contact
If you have any questions about EarthGPT, please feel free to contact w.w.zhanger@gmail.com.

