# üåè EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain

Official repository for [EarthGPT](https://arxiv.org/abs/2401.16822).

Authors: Wei Zhang*, Miaoxin Cai*, Tong Zhang, Yin Zhuang, and Xuerui Mao

\* Equally contributing first authors


## :mega: News
- [2024.01.30]: The Dataset, model, and code are coming soon! :rocket:
* [2024.01.30]: The paper for EarthGPT is released [arxiv](https://arxiv.org/abs/2401.16822). :fire::fire:


##  :sparkles: Introduction
EarthGPT is a pioneering model designed to seamlessly unify multi-sensor and diverse remote sensing intelligent visual interpretation tasks in a unified framework, guided by user language instructions. EarthGPT is versatile at performing visual-language dialogues across optical, SAR, and infrared images. EarthGPT's capabilities extend to a wide range of tasks including scene classification, image description, visual question answering, target description, visual localization, and object detection.
 <div align="center">
  <img src="images/examples.png">
</div>

##  :sparkles: Dataset: MMSM-1M 
the largest multi-modal multi-sensor RS instruction-following dataset named MMRS-1M is constructed, consisting of over 1M image-text pairs that include optical, SAR, and infrared RS images. 

The download link of MMRS-1M is coming soon! üöÄ

